# Snakemake rules to process BAM files
#
# Author: Maurits Evers
# License: GPLv3
# Original date: 22-10-2016
# Last changed: 06-12-2016



#rule dummy:
#    input:
#        expand(join(config["bamdir"], config["refseq"]["id"], "{sample}.sorted.{suf}"), \
#            sample = config["units"].keys(), \
#            suf = ["bam", "bam.bai"])


# Sort and index BAM file
# Note: samtools sort changed its to way specify commandline
# options from version <=0.1.19 to >=1.3.1.
# This will potentially break the workflow
rule samtools_sort_and_index:
    input:
        join(config["bamdir"], config["refseq"]["id"], "{sample}.bam")
    output:
        join(config["bamdir"], config["refseq"]["id"], "{sample}.sorted.bam"),
        join(config["bamdir"], config["refseq"]["id"], "{sample}.sorted.bam.bai")
    version: "1.0"
    shell:
        """
            samtools sort -o {output[0]} {input};
            samtools index {output[0]};
        """


# Mark duplicates using Picard tools
rule mark_duplicates:
    input:
        join(config["bamdir"], config["refseq"]["id"], "{sample}.sorted.bam")
    output:
        join(config["analysisdir"], config["refseq"]["id"], "dupes/{sample}_flaggedDupes.bam"),
        join(config["analysisdir"], config["refseq"]["id"], "dupes/{sample}_metrics.txt")
    params:
        cmd = config["picard"]["cmd"]
    version: "1.0"
    shell:
        """
            {params.cmd} MarkDuplicates \
            I={input} \
            O={output[0]} \
            M={output[1]} 
        """


# Remove duplicates using samtools rmdup
rule samtools_rmdup_and_index:
    input:
        join(config["analysisdir"], config["refseq"]["id"], "dupes/{sample}_flaggedDupes.bam"),
    output:
        join(config["bamdir"], config["refseq"]["id"], "{sample}.sorted.dedup.bam"),
        join(config["bamdir"], config["refseq"]["id"], "{sample}.sorted.dedup.bam.bai")
    params:
        cmd = "samtools"
    version: "1.0"
    shell:
        """
            {params.cmd} rmdup \
            {input} \
            {output[0]};
            samtools index {output[0]}
        """


# Flagstat BAM file
rule flagstat_bam:
    input:
        join(config["bamdir"], config["refseq"]["id"], "{sample}.sorted.dedup.bam")
    output:
        join(config["analysisdir"], config["refseq"]["id"], "flagstat/flagstat_{sample}.txt")
    version: "1.0"
    shell:
        """
            samtools flagstat {input} > {output}
        """


# Estimate insert size using Picard tools
# We need this for the detailed MACS2 peak analysis
rule estimate_insert_size:
    input:
        join(config["bamdir"], config["refseq"]["id"], "{sample}.sorted.dedup.bam")
    output:
        join(config["analysisdir"], config["refseq"]["id"], "insert_size/insert_size_{sample}.txt"),
        join(config["analysisdir"], config["refseq"]["id"], "insert_size/insert_size_{sample}.pdf")
    params:
        cmd = config["picard"]["cmd"],
        ref = REF
    version: "1.0"
    shell:
        """
            {params.cmd} CollectInsertSizeMetrics \
            I={input} \
            H={output[1]} \
            O={output[0]}
        """

        
# Estimate coverage using bedtools
# We need this for the detailed MACS2 peak analysis
rule bedtools_coverage:
    input:
        join(config["bamdir"], config["refseq"]["id"], "{sample}.sorted.dedup.bam")
    output:
        join(config["analysisdir"], config["refseq"]["id"], "coverage/coverage_{sample}.bed")
    params:
        cmd = config["bedtools"]["cmd"],
        ref = REF
    version: "1.0"
    shell:
        """
            {params.cmd} genomecov \
            -ibam {input} \
            -d \
            -g {params.ref} > {output}
        """
        
        
